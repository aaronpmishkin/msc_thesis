%!TEX root = ../main.tex

\chapter{Stochastic Gradient Descent}~\label{ch:sgd}

The discussion in the previous chapter formalized interpolation for general stochastic optimization problems and derived connections between interpolation and the weak/strong growth conditions.  
Now, we turn to the main interest of this work: the complexity of iterative algorithms for \( \rbr{f, \oracle{}} \) when interpolation is satisfied. 
This chapter analyzes the convergence of \ac{SGD} for strongly-convex and convex functions, while the next two chapters tackle \ac{SGD} with the Armijo line-search (\autoref{ch:line-search}) and stochastic acceleration (\autoref{ch:acceleration}).
In particular, this chapter establishes the following non-asymptotic results for \ac{SGD} with a fixed step-size: 
\begin{enumerate}
    \item Linear convergence \emph{in-expectation} for strongly-convex \( f \) when \( \rbr{f, \oracle{}} \) satisfies strong growth; this rate is tight with the best-known deterministic rates when \( \sgc = 1 \).
    \item \emph{Almost sure} linear convergence for strongly-convex \( f \) and individually-smooth and individually-strongly-convex \ac{SFO} \oracle{}. 
    \item Sub-linear convergence for convex \( f \) when \( \rbr{f, \oracle{}} \) satisfies weak growth; our proof is simpler than existing analyses and permits a larger step-size.
    \item Faster sub-linear convergence for convex \( f \) when \( \rbr{f, \oracle{}} \) satisfies weak growth \emph{and} \oracle{} is individually-smooth; this rate is tight with the deterministic case when \( \wgc = 1 \).
\end{enumerate}
\autoref{sec:almost-sure} at the end of this chapter leaves the finite-time regime and considers asymptotic, almost-sure convergence of \ac{SGD} with a fixed step-size under strong and weak growth, respectively.
The following is proved: 
\begin{enumerate}
    \item \ac{SGD} converges to a stationary point of \( f \) when \( \rbr{f, \oracle{}} \) satisfies strong growth.
    \item \ac{SGD} converges to a optimal point \( \wopt \) for convex \( f \) when \( \rbr{f, \oracle{}} \) satisfies weak growth.
\end{enumerate}
This last result is particularly interesting because it concerns convergence of the last input generated by \ac{SGD};
we shall see that such results are not straightforward in the non-asymptotic regime, where convergence is instead shown for an averaged input. 

\begin{figure}[t]
\begin{procedure}{Stochastic Gradient Descent}
\item Choose an initial point \( \w_0 \in \R^d \).
\item For each iteration \( k \geq 0 \):
    \begin{enumerate}
        \item Query \oracle{} for \( \grad(\wk, \zk) \).
        \item Update input as\vspace{-1ex}%
            \[ \wkk = \wk - \eta \grad(\wk, \zk). \]
    \end{enumerate}
\end{procedure}
\caption{Stochastic gradient descent with a fixed step-size \( \eta \). Note that only one query to the stochastic oracle is needed per-iteration.}~\label{procedure:sgd}
\end{figure}

Now, let us briefly introduce \ac{SGD} with a fixed step-size before diving into the analysis.
The basic procedure is given in \autoref{procedure:sgd}; the key components of the algorithm are %
\begin{inparaenum}[(i)] 
    \item the use of a stochastic gradient \( \grad(\wk, \zk) \) queried from the oracle at every iteration, and
    \item the fixed step-size \( \eta > 0 \),
    \item the sequence of inputs \( \seq{\wk} \) generated by the algorithm, which are called the \emph{iterates}. 
\end{inparaenum}
The non-asymptotic rates in this chapter will be derived by analyzing the sequence of distances to a minimizer, \( \seq{\norm{\wk - \wopt}^2} \). 
\autoref{ch:line-search} discusses this proof technique in greater detail and with specific reference to the case where \( \eta \) is itself a random variable that depends on \( \grad(\wk, \zk) \).
We will see that this introduces significant challenges compared to \ac{SGD} with a fixed (deterministic) step-size.\\

\section{Convergence for Strongly-Convex Functions}~\label{sec:sgd-sc}

\subsection{General Oracles}~\label{sec:sgd-sc-general}

We first establish the convergence rate of \ac{SGD} for strongly-convex \( f \) when \( \rbr{f, \oracle} \) satisfies the strong growth condition. 
\autoref{lemma:interpolation_to_sgc} ensures that this is more general than assuming \oracle{} is \( \Lmax \) individually-smooth and \( \rbr{f, \oracle} \) satisfies minimizer interpolation. 
Specifically, the strong growth condition implies that \( \rbr{f, \oracle{}} \) satisfies stationary-point interpolation (which is equivalent to mixed interpolation and weaker than minimizer interpolation when \( f \) is convex) and it's parameter satisfies \( \sgc \leq \frac{\mu}{\Lmax} \) if individual-smoothness and minimizer interpolation hold. 

\begin{restatable}{theorem}{sgcConvex}~\label{thm:sgc-convex}
    Let \( f \) be a \( \mu \)-strongly-convex, \( L \)-smooth function and \( \oracle{} \) a \ac{SFO} such that \( \rbr{f, \oracle{}} \) satisfies the strong growth condition with parameter \( \sgc \).
    Then stochastic gradient descent with fixed step-size \( \eta \leq \frac{2}{\sgc(\mu + L)} \) converges as 
    \[ \E\sbr{f(\wkk)} - f(\wopt) \leq \rbr{\frac{L}{\mu}}\rbr{1 - \frac{2\eta \mu L}{\mu + L}}^k \rbr{f(\w_0) - f(\wopt)}. \] 
\end{restatable}%
\noindent See \autoref{app:sgd-sc} for proof.\hfill \break

We compare this convergence rate to the original result given by \citet[Section 6]{schmidt2013fast} in \autoref{table:sgd-comparison}.
Our analysis allows for a larger step-size and establishes asymptotically faster convergence.
The improvement is most significant for ill-conditioned problems, where \( \mu \ll L \) implies \( \frac{2 L}{\mu + L} \gg 1 \). 
Finally, this result is tight in the sense that when \( \sgc = 1 \), which holds in the deterministic setting, it recovers the best known convergence rate for gradient descent on strongly-convex functions~\citep[Theorem 3.12]{bubeck2015convex}.

When \( \rbr{f, \oracle{}} \) satisfies minimizer interpolation and \oracle{} is individually-smooth, the complexity given by \autoref{thm:sgc-convex} can be worse than that achieved under the weak-growth condition.
For example, consider when the worst-case values \( \sgc = \frac{\mu}{\Lmax} \) and \( \wgc = \frac{\Lmax}{L} \) are attained in the interpolation setting. 
If \( \eta = \frac{2}{\sgc \rbr{\mu + L}} = \frac{2 \mu}{\Lmax\rbr{\mu + L}} \), then \autoref{thm:sgc-convex} guarantees  
\[ \E\sbr{f(\wkk)} - f(\wopt) \leq \rbr{\frac{L}{\mu}}\rbr{1 - \frac{4 \mu^2 L }{\Lmax \rbr{\mu + L}^2}}^k \rbr{f(\w_0) - f(\wopt)}. \]
In contrast, \citet[Theorem 5]{vaswani2019fast} show 
\[ \E\sbr{f(\wkk)} - f(\wopt) \leq \rbr{\frac{L}{\mu}}\rbr{1 - \frac{\mu}{\Lmax}}^k \rbr{f(\w_0) - f(\wopt)}, \]
with a bigger step-size of \( \eta = \frac{1}{\Lmax} \).
Noting \( \frac{4 \mu L}{\rbr{\mu + L}^2} \leq 1 \) --- with equality when \( \mu = L \) --- establishes that the rate given in this work is slower.

The discrepancy in convergence rates for smooth, interpolating oracles emerges from the use of smoothness and strong-convexity in the proof of \autoref{thm:sgc-convex}.
The worst-case value for \( \rho \) is proved using \( \Lmax \)-smoothness of \( f(\cdot, \zk) \) and \( \mu \)-strong-convexity of \( f \) (see \autoref{lemma:interpolation_to_sgc}).
Thus, bounding \( \Ek\sbr{\norm{\grad(\wk, \zk)}^2} \) using strong growth and then following the typical, deterministic proof strategy equates to using smoothness and strong-convexity \emph{twice} and leads to an unnecessarily loose bound.

The above conclusion only holds when \( \rbr{f, \oracle} \) satisfies interpolation and \oracle{} is individually smooth. 
The two convergence speeds cannot be directly compared when \oracle{} is more general because of the cyclic relationship between the strong/weak growth parameters. 
Strong growth implies weak growth with constant \( \alpha = 2 \rho L \),\footnote{This can be shown easily using \autoref{lemma:gradient-bounds}.} while weak growth implies strong growth with constant \( \rho = \alpha \frac{L}{\mu} \).
As a result, no order can be established on \( \alpha \) and \( \rho \) and it is not clear which rate is superior.

\subsection{Individually Smooth and Convex Oracles}~\label{sec:sgd-sgc-ind-convex}

It is possible to improve upon the result from Vaswani et al.\ when \oracle{} further satisfies individual convexity.
In particular, are able to obtain the same convergence speed with a larger bound on the step-size.
A case analysis in \autoref{app:sgd-additional-lemmas} shows that the step-size permitted by \citet[Theorem 5]{vaswani2019fast} is \( \eta \leq \frac{\mu + L}{\alpha L^2} \), which is \( \frac{\mu + L}{L \Lmax}\) in the worst-case.
If \( \mu < L \), then \( \frac{\mu + L}{L \Lmax} < \frac{2}{\Lmax} \) and the following theorem improves upon the original result. 

\begin{restatable}{theorem}{sgcIndConvex}~\label{thm:sgc-ind-convex}
    Let \( f \) be a \( \mu \)-strongly-convex, \( L \)-smooth function and \( \oracle{} \) an \( \Lmax \) individually-smooth, individually-convex \ac{SFO} such that \( \rbr{f, \oracle{}} \) satisfies minimizer interpolation.
    Then stochastic gradient descent with fixed step-size \( \eta < \frac{2}{\Lmax} \) converges as
    \[ \E\sbr{f(\wkk)} - f(\wopt) \leq \rbr{\frac{L}{\mu}}  \rbr{1 - \mu \, \eta \rbr{2 - \eta \Lmax}}^k \rbr{f(\w_0) - f(\wopt)}. \]
\end{restatable}
\noindent See \autoref{app:sgd-sc} for proof.\hfill \break

A key feature of \autoref{thm:sgc-ind-convex} is that it requires only the full function \( f \) to be strongly-convex; the stochastic functions \( f(\cdot, \z) \) may be merely convex, as is typically the case in the finite-sum setting.
To illustrate this, consider the over-determined linear regression problem
\[ \min_{\w \in R^d} \sum_{i=1}^n \rbr{\abr{\w, x_i} - y_i}^2, \]
where \( d \ll n \).
The individual functions \( f_i(\w) = \rbr{\abr{\w, x_i} - y_i}^2 \) are clearly not strongly-convex,\footnote{To see this, consider the points \(w\) and \( \w' = \w + v \), where \( v \) is orthogonal to \( x_i \).} but \( f \) is as long as the data-matrix \( X \) is full-rank. 
However, in the unlikely case that if \oracle{} is also individually-strongly-convex, we can show that \ac{SGD} will converge almost surely, as established in the following theorem.

\begin{restatable}{theorem}{sgcIndSC}~\label{thm:sgc-ind-sc}
    Let \( f \) be a \( \mu \)-strongly-convex, \( L \)-smooth function and \( \oracle{} \) an \( \Lmax \) individually-smooth, \( \mumax \)-individually-strongly-convex \ac{SFO} such that \( \rbr{f, \oracle{}} \) satisfies minimizer interpolation. 
    Then stochastic gradient descent with fixed step-size \( \eta \leq \frac{2}{\mumax + \Lmax} \) converges deterministically at the rate 
    \[ f(\wkk) - f(\wopt) \leq \rbr{\frac{L}{\mu}} \rbr{1 - 2 \eta \, \delta_{\text{max}} }^k \rbr{f(\w_0) - f(\wopt)}, \] 
    where \( \delta_{\text{max}} = \max_{\z \in \calZ} \frac{\mu_\z L_\z}{\mu_\z + L_\z} \).
\end{restatable}%
\noindent See \autoref{app:sgd-sc} for proof.\hfill \break

\autoref{thm:sgc-ind-sc} is not surprising; strongly-convex functions have only one minimizer, meaning that gradient-descent on a single stochastic function \( f(\cdot, \zk) \) is sufficient to recover the global minimizer.
Choosing the best-conditioned sub-function function yields convergence to \( \wopt \) as \( O\rbr{\exp\cbr{ - 2 \eta \, \delta_{\text{min}} \, K}} \), where \( \delta_{\text{min}} = \min_{\z \in \calZ} \frac{\mu_z L_\z}{\mu_z + L_\z} \)~\citep{bubeck2015convex}.
Notice that we have exchanged worst-case performance for best-case (\( \delta_{\text{max}} \) vs \( \delta_{\text{min}} \)) by optimizing \( f(\cdot, \z) \) directly.
\ac{SGD} is clearly sub-optimal when \oracle{} is individually-strongly-convex and the optimization procedure has direct access to \( f(\cdot, \z ) \) for each \( \z \in \calZ \), such as in the finite-sum setting. 
This illustrates the dangers of assuming individual strong-convexity and interpolation hold simultaneously.


\section{Convergence for Convex Functions}~\label{sec:sgd-convex}

From the perspective of the optimizer, convex functions are significantly more interesting than strongly-convex functions when interpolation is satisfied. 
Minimizer interpolation for convex functions implies \( \calX^* \subseteq \calX^*_{\z} \) --- the optimal set for \( f \) is a subset of the optimal set for \( f(\cdot, \z) \).
This condition intuitively feels milder than the requirement for a shared optimal point \( \wopt \). 
Moreover, assuming individual convexity does not lead to degenerate optimization problems such as those seen in the previous section.
Convex functions also require a major shift in analysis; now we shall show concentration of the optimality gap \( f(\w) - f(\wopt) \), rather than shrinking distance to a specific minimizer, \( \norm{\w - \wopt}^2 \).

We first establish the convergence rate of \ac{SGD} for convex functions under the weak growth condition. 
As before, it is strictly more general to analyze the complexity of \ac{SGD} under weak growth than in the setting where \oracle{} is individually-smooth and minimizer interpolation holds. 
Specifically, \autoref{lemma:interpolation-to-wgc} guarantees \( \wgc \leq \frac{\Lmax}{L} \) in such a case. 
The following result improves on that given by \citet{vaswani2019fast} by constant factors and allows for a larger step-size (see \autoref{table:sgd-comparison}).  
Moreover, the proof in \autoref{app:sgd-convex} is simpler and far shorter. 

\begin{restatable}{theorem}{wgcConvex}~\label{thm:wgc-convex}
    Let \( f \) be a convex, \( L \)-smooth function and \oracle{} a \ac{SFO} such that \( \rbr{f, \oracle{}} \) satisfies the weak growth condition with parameter \( \wgc \).
    Then stochastic gradient descent with fixed step-size \( \eta < \frac{1}{\wgc L} \) converges as
    \[ \E\sbr{\f(\bar \w_K)} - f(\wopt) \leq \frac{1}{2 \eta \rbr{1 - \eta \wgc L} \, K} \norm{\w_0 - \wopt}^2, \]
    where \( \bar \w_K = \frac{1}{K} \sum_{k=0}^{K-1} \wk \). 
\end{restatable}

In fact, a slightly larger step-size and faster convergence rate can be obtained when \( \oracle{} \) is individually smooth.
We show this now.

\begin{restatable}{theorem}{wgcConvexIndSmooth}~\label{thm:wgc-convex-ind-smooth}
    Let \( f \) be a convex, \( L \)-smooth function and \oracle{} a \ac{SFO} such that \( \rbr{f, \oracle{}} \) satisfies the weak growth condition with parameter \( \wgc \).
    Moreover, suppose \oracle{} is \( \Lmax \) individually-smooth. 
    Then stochastic gradient descent with fixed step-size \( \eta < \frac{1}{\wgc L} + \frac{1}{\Lmax} \) converges as
    \[ \E\sbr{f(\bar w_K)} - f(\wopt) \leq \frac{1}{2\eta \, \delta \, K} \norm{\w_0 - \wopt}^2,   \]
    where \( \bar \w_K = \frac{1}{K} \sum_{k=0}^{K-1} \wk \) and \( \delta = \min \cbr{ 1, 1 + \wgc L \rbr{\frac{1}{\Lmax} - \eta }} \). 
\end{restatable}
\noindent See \autoref{app:sgd-convex} for proof. \hfill \break

\autoref{thm:wgc-convex-ind-smooth} is tight with the deterministic case in the following sense: if \( f(\cdot, \z) = f \) for each \( z \in \calZ \), then \( \wgc = 1 \), \( \Lmax = L \), and the rate given is comparable to the best known results in the deterministic setting (cf. \citet[Theorem 3.3]{bubeck2015convex}). 
This result also further illustrates the benefits of directly assuming the weak growth condition, since the maximum step-size satisfies 
\( \frac{1}{\wgc L} + \frac{1}{\Lmax} \geq \frac{2}{\Lmax}, \)
where \( \frac{2}{\Lmax} \) is the condition obtained when deriving weak growth directly from individual smoothness and minimizer interpolation.
\todo{Cannot directly compare the strongly-convex cases because fast and faster uses weak growth. Mismatch in \( \rho \). }
\begin{table}[t]
    \centering
    \begin{tabular}{c l l c c  }\toprule
        \multirow{2}{*}{Assumptions} & \multicolumn{2}{c}{Max. Step-Size}  & \multicolumn{2}{c}{Convergence Rate}\\%
        \cmidrule(lr){2-3} \cmidrule(l){4-5}
                 & \multicolumn{1}{c}{Ours} & \multicolumn{1}{c}{VBS~\citep{vaswani2019fast}} & \multicolumn{1}{c}{Ours} & \multicolumn{1}{c}{VBS~\citep{vaswani2019fast}}\\ \midrule
    \( \mu \)-SC & \( \eta \leq \frac{2}{\sgc\rbr{\mu + L}} \)% 
                 & \( \eta \leq \frac{1}{\sgc L} \)%
                 & \( O\rbr{\exp\cbr{- \rbr{\frac{2 \eta \mu L}{\mu + L}} \, K}} \)% 
                 & \( O\rbr{\exp\cbr{- \eta \mu \, K }} \) \\ \addlinespace
    Convex       & \( \eta < \frac{1}{\wgc L} \)%
                 & \( \eta < \frac{1}{2 \wgc L} \)%
                 & \( O\rbr{\frac{1}{2 \eta (1 - \eta \wgc L) \, K}} \)%
                 & \( O\rbr{\frac{2 - \eta L\rbr{1 - 2 \eta \wgc L}}{\eta (1- 2 \eta \wgc L) \, K} } \)\\ \addlinespace 
    \makecell{Convex + \\ Ind. Smooth}% 
                 & \( \eta \leq \frac{1}{\wgc L} + \frac{1}{\Lmax} \)%
                 & \multicolumn{1}{c}{N/A}% 
                 & \( O\rbr{\frac{1}{2 \eta \, \delta \, K}} \)%
                 & \multicolumn{1}{c}{N/A} \\ \bottomrule 
    \end{tabular}
    \caption{Comparison of convergence rates for fixed step-size \ac{SGD}. Recall from \autoref{thm:wgc-convex-ind-smooth} that \( \delta = \min \cbr{ 1, 1 + \wgc L \rbr{\frac{1}{\Lmax} - \eta }} \). Our results are tighter than VBS (Vaswani-Bach-Schmidt~\citep{vaswani2019fast}) and allow for larger step-sizes.}%
    \label{table:sgd-comparison}
\end{table}


\section{Almost Sure Convergence}~\label{sec:almost-sure}

Now we briefly change paradigms and consider the asymptotic behavior of \ac{SGD} with a fixed step-size.
Our overall goal in this section is to show the almost-sure (with probability 1) convergence of \ac{SGD} to a minimizer or stationary point of \( f \) when \( \rbr{f, \oracle{}} \) satisfy weak or strong growth, respectively.
In particular, we want to show that the random variable \( \lim_{\iter \rightarrow \infty} \norm{\grad(\wk)}^2 \) exists and is almost-surely zero.
We will need some tools from measure-theoretic probability to accomplish this.
To start, we note that each iterate \( \w_k \) can be written as deterministic Borel function of the stochastic gradients \( \cbr{\grad(\wk, \zk)}_{\iter=0}^{K} \) by unrolling the \ac{SGD} update.
Formally, we also assume a probability space \( \rbr{\Omega,  \calF, P} \) in the background and say the sequence \( \seq{\wk} \) is \emph{adapted} to the filtration generated by the stochastic gradients,
\begin{align*}
    \calF_K = \sigma \rbr{\bigcup_{\iter = 0}^{K-1} \sigma \grad(\wk, \zk)}.
\end{align*}
The sequences of function and gradient values are functions of \( \seq{\wk} \) and so are also adapted to \( \seq{\calF_\iter} \).
See \citet{ccinlar2011probability} additional details on filtrations.

Our main tool to show convergence of sequences of random variables will be supermartingale theory~\citep{ccinlar2011probability}.
Supermartingales are one of two classic tools used analyze the convergence of \ac{SGD}, the other being Lyapunov functions~\citep{bertsekas2000gradient}.
In particular, recent authors have made use of convergence of discrete-time, positive supermartingales~\citep{bertsekas2011incremental, nguyen2018sgd}.
This theorem is due to~\citet{neveu1975discrete} and will be the cornerstone of our analyses; we reproduce it here for convenience.

\begin{theorem}[Convergence of Positive Supermartingales]\label{thm:positive_supermartingales}
    Let \( \seq{Y_\iter} \), \( \seq{X_\iter} \), and \( \seq{A_\iter} \) be discrete, non-negative random processes indexed by \( \iter \in \bbN \) and adapted to the filtration \( \seq{\calF_\iter} \).
    Suppose that
    \begin{align*}
        \forall \iter \in \bbN, \: \E \sbr{Y_{\iter+1} \mid \calF_\iter} \leq Y_\iter - X_\iter + A_\iter,
        && \text{ and } &&
        \sum_{k=0}^{\infty} A_\iter < \infty,
    \end{align*}
    almost surely.
    Then the sequence \( \seq{Y_\iter} \) converges almost surely to a non-negative random variable \( Y_\infty \) and \( \sum_{k=0}^{\infty} X_\iter < \infty \) almost surely.
\end{theorem}
With necessary the measure-theoretic background complete, we are now ready to study the almost-sure convergence of stochastic gradient descent.

\begin{restatable}{theorem}{wgcAlmostSure}~\label{thm:wgc-almost-sure}
    Let \( \f \) be a convex, \( L \)-smooth function with at least one finite minimizer and \oracle{} a \( \Lmax \) individually-smooth \ac{SFO} such that \( \rbr{f, \oracle{}} \) satisfy the weak growth condition with parameter \( \wgc \).
    Then stochastic gradient descent with fixed step-size \( \eta < \frac{1}{\wgc L} + \frac{1}{\Lmax} \) converges to a minimizer of \( f \) almost surely,
\end{restatable}

The proof is given in \autoref{app:almost-sure-convergence} and follows a straightforward argument.
First, we establish that the sequence of distances to a finite minimizer \( \seq{\norm{\wk - \wopt}^2} \) satisfies the conditions of Theorem~\ref{thm:positive_supermartingales}.
As by-product, we obtain that the series \( \sum_{k=0}^{\infty} \rbr{f(\wk) - f(\wopt)} \) is convergent and then deduce
\[ \lim_{k\rightarrow\infty} \wk \in \argmin_w f(\w), \] 
almost surely using the weak growth condition.
It is straightforward to prove an alternative version of \autoref{thm:wgc-almost-sure} which does not require individual smoothness.
In this case, convergence is established for \( \eta < \frac{1}{\wgc L} \) using the same progress condition as in \autoref{thm:wgc-convex}, namely \autoref{eq:cwg-alternate-progress}.

\autoref{thm:wgc-almost-sure} holds for the \emph{final} iterate generated by the \ac{SGD} procedure.
This should be contrasted with with Theorems~\ref{thm:wgc-convex} and~\ref{thm:wgc-convex-ind-smooth}, which apply only to the averaged iterate \( \bar \wk \).
While the existence of an asymptotic result suggests that non-asymptotic, final-iterate convergence for constant step-size \ac{SGD} under the weak growth condition is possible, we do not establish such a result in this work. 
Convergence (or non-convergence) of the final iterate remains an interesting and surprisingly simple open problem in optimization under interpolation.

The final result of this chapter shows almost-sure convergence to a stationary point for general non-convex functions \( f \) such that \( \rbr{f, \oracle{}} \) satisfy the strong growth condition.
The proof is presented in \autoref{app:almost-sure-convergence} and follows a similar structure to the proof of \autoref{thm:wgc-almost-sure}.

\begin{restatable}{theorem}{sgcAlmostSure}~\label{thm:sgc-almost-sure}
    Let \( \f \) be an \( L \)-smooth function and \oracle{} a SFO such that \( \rbr{f, \oracle{}} \) satisfy the strong growth condition with parameter \( \sgc \).
    Then stochastic gradient descent with fixed step-size \(\eta < \frac{2}{\sgc L} \) converges to a stationary point of \( f \) almost surely.
\end{restatable}

\endinput

