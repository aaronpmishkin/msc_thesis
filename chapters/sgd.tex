%!TEX root = ../main.tex

\chapter{Stochastic Gradient Descent}~\label{ch:sgd}


\section{Convergence for Strongly-Convex Functions}~\label{sec:sgd-sc}

We establish the convergence rate of SGD for strongly-convex under the strong growth condition. 
The following theorem allows for a larger step-size and establishes asymptotically faster convergence than the corresponding theorem in \citet{vaswani2019fast}.

\begin{restatable}{theorem}{sgcConvex}~\label{thm:sgc-convex}
    Let \( f \) be a \( \mu \)-strongly-convex, \( L \)-smooth function satisfying the strong growth condition with constant \( \rho \).
    Then stochastic gradient descent with step-size \( \eta \leq \frac{2}{\rho(\mu + L)} \) converges as 
    \[ f(\wk) - f(\wopt) \leq \rbr{\frac{L}{\mu}}\rbr{1 - \frac{2\eta \mu L}{\mu + L}}^k \rbr{f(\w_0) - f(\wopt)}. \] 
\end{restatable}

See \autoref{app:sgd-sc} for proof.
A key feature of this theorem is is that it requires only the full function \( f \) to be strongly-convex; the individual/stochastic functions \( f(\cdot, \z) \) may be merely convex, as is typically the case in the finite-sum setting.
Stochastic gradient descent is sub-optimal if the stochastic functions are also strongly-convex and the optimization procedure has direct access to \( f(\cdot, \z ) \) for each \( \z \).
In this case, gradient descent on the stochastic function with smallest condition number \( \kappa_{\text{min}} \) converges to the global minimize of the full function \( f \) as \( O\rbr{\exp\cbr{\frac{-4 k}{\kappa_{\text{min}} + 1}}} \).
Despite being a poor algorithmic choice, SGD will converge deterministically in this setting, as established in the following theorem.

\begin{restatable}{theorem}{sgcIndSC}~\label{thm:sgc-ind-sc}
    Let \( f \) be a \( \mu \)-strongly-convex, \( L \)-smooth function satisfying the strong growth condition with constant \( \rho \).
    Furthermore, assume that the stochastic functions \( f(\cdot, \z) \) are (i) \( \mu_\z \)-strongly-convex and (ii) \( L_\z \)-smooth.
    Let \( \mumax \) and \( \mumin \) be the largest and smallest strong-convexity constants for the stochastic functions, respectively.
    Similarly, let \( \Lmax \) and \( \Lmin \) be the largest and smallest Lipschitz constants of the stochastic gradients.
    Then stochastic gradient descent with step-size \( \eta \leq \frac{2}{\mumax + \Lmax} \) converges deterministically at the rate 
    \[ f(\wkk) - f(\wopt) \leq \frac{L}{\mu} \rbr{1 - \frac{2 \eta \mumin \Lmin}{\mumax + \Lmax}}^k \rbr{f(\w_0) - f(\wopt)}. \] 
\end{restatable}


\section{Convergence for Convex Functions}~\label{sec:sgd-convex}
\todo{Clarify the improvements in this proof}

We establish the convergence rate of SGD for convex functions under the weak growth condition. These results improve on those given by \citet{vaswani2019fast} by constant factors. 
Moreover, we provide cleaner and simpler proofs.


\begin{restatable}{theorem}{wgcConvex}~\label{thm:wgc-convex}
    Let \( f \) be a convex, \( L \)-smooth function satisfying the weak growth condition with constant \( \rho  \).
    Then stochastic gradient descent with step-size \( \eta < \frac{1}{\rho L} \) converges as
    \[ \f(\bar \w_K) - f(\wopt) \leq \frac{1}{2 \eta \rbr{1 - \eta \rho L} \, K} \norm{\w_0 - \wopt}^2, \]
    where \( \bar \w_K = \frac{1}{K} \sum_{k=0}^K \wk \). 
\end{restatable}

A slightly larger step-size can be obtained if we further assume that the stochastic functions are themselves Lipschitz-smooth.

\begin{restatable}{theorem}{wgcConvexIndSmooth}~\label{thm:wgc-convex-ind-smooth}
    Let \( f \) be a convex, \( L \)-smooth function satisfying the weak growth condition with constant \( \rho  \).
    Moreover, suppose that the stochastic functions \( f(\cdot, \z) \) are \( L_\z \)-smooth for each \( \z \), with \( \Lmax = \max_\z L_\z \).
    Then stochastic gradient descent with step-size \( \eta < \frac{1}{\rho L} + \frac{1}{\Lmax} \) converges as
    \[ \E\sbr{f(\bar w_K)} - f(\wopt) \leq \frac{1}{2\eta \, C \, K} \norm{\w_0 - \wopt}^2,   \]
    where \( \bar \w_K = \frac{1}{K} \sum_{k=0}^K \wk \) and \( C = 1 + \min \cbr{ 0, \rho L \rbr{\frac{1}{\Lmax} - \eta }} \). 
\end{restatable}

See \autoref{app:sgd-convex} for proof.

\section{Almost Sure Convergence}

Our overall goal is to characterize the asymptotic behavior of SGD.
In particular, we want to show that the random variable \( \lim_{\iter \rightarrow \infty} \norm{\grad(\wk)}^2 \) exists and is almost-surely zero.
We will need some tools from measure-theoretic probability to accomplish this.
To start, we note that each iterate \( \w_K \) can be written as deterministic function of the stochastic gradients \( \cbr{\grad(\wk, \zk)}_{\iter=0}^{K} \) by unrolling the SGD update.
Formally, we assume a probability space \( \rbr{\Omega,  \calF, P} \) in the background and say the sequence \( \seq{\wk} \) is \emph{adapted} to the filtration generated by the stochastic gradients,
\begin{align*}
    \calF_K = \sigma \rbr{\bigcup_{\iter = 0}^{K-1} \sigma \grad(\wk, \zk)}.
\end{align*}
The sequences of function and gradient values are functions of \( \seq{\wk} \) and so are also adapted to \( \seq{\calF_\iter} \).
See \citet{ccinlar2011probability} additional details on filtrations.

Our main tool to show convergence of sequences of random variables will be supermartingale theory~\citep{}.
Supermartingales are one of two classic tools used analyze the convergence of SGD, the other being Lyapunov functions~\citep{bertsekas2000gradient}.
In particular, recent authors have made use of convergence of discrete-time, positive supermartingales~\citep{bertsekas2011incremental, nguyen2018sgd}.
This theorem is due to~\citet{neveu1975discrete} and will be the cornerstone of our analyses; we reproduce it here for convenience.

\begin{theorem}[Convergence of Positive Supermartingales]\label{thm:positive_supermartingales}
    Let \( \seq{Y_\iter} \), \( \seq{X_\iter} \), and \( \seq{A_\iter} \) be discrete, non-negative random processes indexed by \( \iter \in \bbN \) and adapted to the filtration \( \seq{\calF_\iter} \).
    Suppose that
    \begin{align*}
        \forall \iter \in \bbN, \: \E \sbr{Y_{\iter+1} \mid \calF_\iter} \leq Y_\iter - X_\iter + A_\iter,
        && \text{ and } &&
        \sum_{k=0}^{\infty} A_\iter < \infty,
    \end{align*}
    almost surely.
    Then the sequence \( \seq{Y_\iter} \) converges almost surely to a non-negative random variable \( Y_\infty \) and \( \sum_{k=0}^{\infty} X_\iter < \infty \) almost surely.
\end{theorem}
With this necessary martingale theorem in hand, we are now ready to study the almost-sure convergence of stochastic gradient descent.

\begin{restatable}{theorem}{wgcAlmostSure}~\label{theorem:wgc-almost-sure}
    Let \( \f \) be an \( L \)-smooth, convex function that is bounded below.
    Assume that \( f \) has at least one finite minimizer \( \wopt \).
    Moreover, suppose that the stochastic functions \( f(\cdot, \z) \) are \( L_\z \)-smooth for each \( \z \), with \( \Lmax = \max_\z L_\z \).
    If \( f \) satisfies the weak growth condition with parameter \( \rho \), then stochastic gradient descent with step-size \( \eta < \frac{1}{\rho L} + \frac{1}{\Lmax} \) converges to \( \fopt \) almost surely.
\end{restatable}

\todo{note that the conditions can be relaxed not avoid individual smoothness at the cost of a larger step-size.}

\begin{restatable}{theorem}{sgcAlmostSure}~\label{theorem:sgc-almost-sure}
    Let \( \f \) be an \( L \)-smooth function that is bounded below and satisfies the strong growth condition with parameter \(\rho \).
    Then stochastic gradient descent with fixed step-size \(\eta < \frac{2}{\rho L} \) converges to a stationary point almost surely.
\end{restatable}

\endinput
