%! TEX root = ../main.tex

\chapter{Interpolation and Growth Conditions}~\label{ch:interpolation-gc}



%% Oracle Model
\section{Stochastic Oracles}~\label{sec:stochastic-oracles}
% As stated above, this work is primarily concerned with the analysis of iterative methods for stochastic optimization.
The defining feature of stochastic optimization algorithms is that they cannot directly access the value or gradient of \( f \).
Instead, they obtain noisy function and gradient evaluations through a \ac{SFO}  \oracle. 
At each iteration \( k \), \oracle{} outputs a stochastic function and gradient \( f(v, \zk) \) and \( \grad(v, \zk) \) at query point \( v \), where \( \zk \) is a random variable with distribution \( \mu_k \) supported on \( \calZ_k \subseteq \R^m \), \( m > 0 \).%%
\footnote{It will be sufficient to treat the measure \( \mu_k \) as a prob.\ density function \( p_k \) for nearly all of our purposes.}
We assume that \( f(v, \cdot) \) is a deterministic Borel function, meaning the randomness in \( f(v, \zk) \) stems only from the random variable \( \zk \).
Similarly, \( \grad(v, \cdot) \) is taken to be a deterministic Borel function related to \( f(v, \cdot) \) through the standard differentiation operator,
\[ \grad(v, \cdot) = \sbr{\partial_{v_1} f(v, \cdot), \ldots, \partial_{v_d} f(v, \cdot)}^\top. \]
Unless stated otherwise, the oracle outputs are always taken to be unbiased, implying that 
\begin{align*}
    \E_{\zk} \sbr{f(v, \zk)} = f(v) \quad \text{and} \quad \E_{\z} \sbr{\grad(v, \zk)} = \grad(v), 
\end{align*}
for all \( k \geq 0 \).

The definition of \oracle{} is non-stationary in the sense that it allows the distributions \( \mu_k \) and their support \( \calZ_k \) to change across iterations.
As such, it will be necessary to refer to the support of the entire stochastic process \( \seq{\zk} \), 
\[ \calZ = \bigcup_{k\geq 0} \calZ_k. \]
For simplicity, \( \calZ \) is termed the support of \oracle{}. 
Note that a statement which holds point-wise over \( \calZ \) holds almost-surely for all \( \zk \).
Indeed, these two requirements are equivalent, since (by definition) every \( \z \in \calZ \) is in the support of some \( \mu_k \).
We will make use of this less cumbersome notation. 

Some results will further require that the stochastic function \( f(\cdot, \zk) \) is Lipschitz-smooth in the first argument for all outcomes in \( \calZ \).
In this case, we say \oracle{} satisfies \emph{individual smoothness} with parameter \( \Lmax \).
\begin{restatable}[Individual Smoothness]{definition}{individuallySmooth}~\label{def:individually-smooth}
    A \ac{SFO} \oracle{} is called \( \Lmax \) individually-smooth if the stochastic gradient mapping \( \w \mapsto \grad(\w, \z) \) is \( L_{\z} \)-Lipschitz with \( L_{\z} \leq \Lmax \) for all \( \z \in \calZ \).
\end{restatable}
Individual smoothness implies the quadratic upper bound
\[ f(v, \z) \leq f(\w, \z) + \abr{\grad(\w, \z), v - \w} + \frac{\Lmax}{2}\norm{v - \w}^2 \quad \forall v, \w \in \R^d, \]
holds point-wise over \( \calZ \) and thus almost-surely for each \( \zk \).
Note that the existence of an \( \Lmax \) individually-smooth, unbiased \ac{SFO} for \( f \) implies that \( f \) is \( L \)-smooth with \( L \leq \Lmax \) as an immediately corollary.
\begin{restatable}{corollary}{indSmoothToSmooth}~\label{cor:ind-smooth-to-smooth}
    Let \( f : \R^d \rightarrow \R \) be a differentiable function.  
    If there exists an unbiased, \( \Lmax \) individually-smooth \ac{SFO} \oracle{} for \( f \), then \( f \) is \( L \)-smooth with \( L \leq \Lmax \).
    Alternatively, if \( \oracle{} \) is biased but \( \calZ \) is finite, then \( \Ek \sbr{f(\cdot, \zk)} \) is \( \Lmax \)-smooth for all \( k \). 
\end{restatable}
See \autoref{app:stochastic-oracles} for proof. 
In several cases, we will also make use of individual strong-convexity.
\begin{restatable}[Individual Strong-Convexity]{definition}{individuallySC}~\label{def:individually-sc}
    A \ac{SFO} \oracle{} is called \( \mumax \) individually-strongly-convex if the stochastic function \( f(\w, \z) \) is \( \mu_{\z} \)-strongly-convex with \( \mu_{\z} \leq \mumax \) for all \( \z \in \calZ \).
    If \( \mumax = 0 \), then we say \oracle{} is merely individually-convex.
\end{restatable}

Individually-smooth oracles are wide-spread throughout machine learning in the form of finite-sum functions. 
Finite-sum functions are a particular class of structured optimization problem where the objective \( f \) is the sum of \( n \) sub-functions. 
This is written as
\begin{align*}
    f(\w) = \frac{1}{n} \sum_{i = 0}^n f_i(\w), 
\end{align*}
where the functions \( f_i : \R^d \rightarrow \R \) may be strongly-convex, convex, or non-convex depending on the problem.
Such objective functions arise naturally in empirical risk minimization (ERM), where each \( f_i \) typically corresponds to a example \( (x_i, y_i) \) in a training set.
For example, the classic least-squares regression problem 
\[ \wopt = \argmin \frac{1}{n} \sum_{i=1}^n \rbr{\abr{w, x_i} - y_i}^2, \]
has a finite-sum structure with \( f_i(\w) =  \rbr{\abr{w, x_i} - y_i}^2\).
A simple \ac{SFO} can be obtained in this setting by uniformly sub-sampling \( m < n \) examples from the finite-sum; this yields the following gradient and function estimates:
\[ f(\w, \zk) = \frac{1}{|\zk|} \sum_{i \in \zk} f_i(\w) \; \text{ and } \grad(\w, \zk) = \frac{1}{|\zk|} \sum_{i \in \zk} \grad_i(\w). \]
The support set of \oracle{} is then \( \calZ = \cbr{ A \subseteq \cbr{1, \dots, n} : |A| = m } \).
It is straightforward to show that these \emph{mini-batch} function and gradient estimators are unbiased.
Moreover, if the individual functions \( f_i \) are individually \( L_i \)-smooth, then the mini-batch \ac{SFO} satisfies individual-smoothness with \( \Lmax = \max_{i\in [n]} L_i \).
We call general \acp{SFO} \oracle{} individually-smooth specifically to invite comparison with this natural property in the finite-sum setting. 


\section{Interpolation}~\label{sec:interpolation}

In this section, we formalize what it means for an optimization problem to satisfy interpolation.
Specifically, we develop several notions of interpolation as a property of an objective-\ac{SFO} pair in a similar fashion as was done for individual-smoothness.
As with individual smoothness, interpolation will be shown to have a interpretation for finite-sum functions that satisfies the standard intuition for the meaning of interpolation in function approximation and machine learning. 

Interpolation can be formalized in the following three ways:
\begin{definition}[Interpolation: Minimizers]\label{def:interpolation-minima}
    A function-oracle pair \( (f, \oracle{}) \) satisfies minimizer interpolation if for all \( \z \in \calZ \),
    \[ f(\wopt) \leq f(\w) \; \forall \w \in \R^d \implies f(\wopt, \z) \leq f(\w, \z) \; \forall \w \in \R^d.  \]
\end{definition}
\begin{definition}[Interpolation: Stationary Points]\label{def:interpolation-gradients}
    A function-oracle pair \( (f, \oracle{}) \) satisfies stationary-point interpolation if for all \( \z \in \calZ \),
    \[ \grad(\wopt) = 0 \implies \grad(\wopt, \z) = 0. \]
\end{definition}
\begin{definition}[Interpolation: Mixed]\label{def:interpolation-mixed}
    A function-oracle pair \( (f, \oracle{}) \) satisfies mixed interpolation if for all \( \z \in \calZ \),
    \[ f(\wopt) \leq f(\w) \; \forall \w \in \R^d \implies \grad(\wopt, \z) = 0. \]
\end{definition}
The axis of variation in these definitions is whether the interpolation requirement is placed on minimizers or stationary points of the function \( f \).
In words, \autoref{def:interpolation-minima} states that global minimizers of the objective \( f \) must be global minimizers of the stochastic functions given by the \ac{SFO} almost surely at every iteration \( k \).
In contrast, \autoref{def:interpolation-gradients} puts the same requirement on stationary points of \( f \), while \autoref{def:interpolation-mixed} merely demands that minimizers of \( f \) are stationary points of \( f(\cdot, \z) \) for all outcomes \( \z \).

For general functions and \acp{SFO}, the relationship between these models of interpolation is limited to the following: minimizer interpolation and stationary-point interpolation are stronger than mixed interpolation. 
However, when \( f \) is invex, all three definitions are equivalent.
This is stated in the following lemma.
\begin{restatable}{lemma}{interpRelationships}~\label{thm:interp-relationships}
    Let \( \rbr{f, \oracle{}} \) be an arbitrary function-\ac{SFO} pair. 
    Then only the following relationships hold between models of interpolation:
    \begin{align*}
        \text{Minimizer Interpolation} \; (\autoref{def:interpolation-minima}) &\implies \; \text{Mixed Interpolation} \; (\autoref{def:interpolation-mixed})\\
                                                                               & \text{and} &\\
        \text{Stationary-Point Interpolation} \; (\autoref{def:interpolation-gradients}) &\implies \; \text{Mixed Interpolation} \; (\autoref{def:interpolation-mixed}).
    \end{align*}
    However, if \oracle{} is such that \( f(\cdot, \z) \) is invex for all \( \z \in \calZ \), then minimizer, stationary-point, and mixed interpolation are equivalent.
\end{restatable}
This result follows immediately from first-order optimality conditions and the equivalence of stationary points and global minimizers for invex functions.
For completeness, a short proof with counter-examples for the implications which do not hold is given in \autoref{app:interpolation-gc}.


\begin{figure}[]
    \centering
    \includegraphics[width=0.28\linewidth]{example-image-a}
    \includegraphics[width=0.28\linewidth]{example-image-b}
    \includegraphics[width=0.28\linewidth]{example-image-c}
    \caption{Differences in interpolation definitions in the finite-sum setting.}%
    \label{fig:interpolation-types}
\end{figure}

Let us return to the finite-sum setting and use a mini-batch oracle to better understand these three definitions of interpolation.
In particular, let \( f \) and \oracle{} be such that
\[ f(\w) =  \frac{1}{n} \sum_{i=1}^{n} f_i(\w), \quad f(\w, \zk) = f_{\zk}(\w), \quad \grad(\w, \zk) = \grad_{\zk}(\w),  \]
where \( \mu_k \) is a uniform distribution over the support set \( \calZ = \cbr{1, \ldots, n} \).
The function-oracle pair \( \rbr{f, \oracle{}} \) satisfy minimizer (stationary-point) interpolation if the individual functions \( f_i \) are globally minimized (stationary) at every global minimum (stationary point) of \( f \).
The differences between minimizer and stationary-point interpolation are readily apparent for finite-sums of non-convex functions, as show in \autoref{fig:interpolation-types}.
If we further narrow this to linear regression, where \( f_i(\w) = \rbr{\abr{\w, x_i} - y_i}^2 \) for a data point \( \rbr{x_i, y_i} \), then it becomes obvious that minimizer interpolation implies the entire training set can be fit exactly, or interpolated.
Thus, \autoref{def:interpolation-minima} exactly fits the intuition for interpolation in the context of function approximation.

There are several natural ways to establish interpolation.
Linear regression problems satisfy interpolation when \( d \geq n \).
Separable binary classification also trivially satisfies interpolation.
In the general setting of \acp{SFO}, the follow lemma establishes simple conditions for a \( \rbr{f, \oracle{}} \) to satisfy minimizer interpolation.
\begin{restatable}{lemma}{boundedBelow}~\label{thm:bounded-below}
    A function-oracle pair \( \rbr{f, \oracle{}} \) satisfies minimizer interpolation (\autoref{def:interpolation-minima}) if \oracle{} is unbiased and 
    \[ f(\w, \z ) \geq f(\wopt) \; \forall \w \in \R^d,  \quad \forall \z \in \calZ. \]
\end{restatable}
\todo{Expand this section on identifying/establishing interpolation conditions}\\
\todo{Minimizer interpolation is the most natural. Expand on this?}

\section{Growth conditions}\label{sec:growth_conditions}
\todo{This is equivalent to bounding the variance, which is quite common. There should be a whole bunch of citations by Lan.}

Interpolation is directly related to the idea of placing \emph{growth conditions} on the stochastic gradients.
Informally, growth conditions are a class of regularity condition that constrain the noise in \( \grad(v, \wk) \) in terms of the objective \( f \).
For example, the following condition was used as early as the classical analysis of stochastic optimization algorithms by \citet{poljak1973pseudogradient}, and continues to appear in current work~\citep{bertsekas2000gradient, khaled2020better}  
\[ \Ek \sbr{\norm{\grad(v, \zk)}^2} \leq \rho \norm{\grad(v)}^2 + \sigma^2,  \]
where \( \rho, \sigma \geq 0 \).
\citet{tseng1998incremental} and \citet{solodov1998incremental} strengthened this condition to require the maximum stochastic gradient norm to be almost surely bounded by the true gradient.
\todo{Note that this was in the context of deterministic incremental gradient methods.}
Following~\citet{khaled2020better}, we call this condition maximal strong growth.
\begin{definition}[Maximal Strong Growth]~\label{def:maximal-sg}
    A function-oracle pair \( \rbr{f, \oracle{}} \) satisfies maximal strong growth if  
    \begin{align*}
        \norm{\grad(\w, \z)}^2 \leq \rho \norm{\grad(x)}^2, 
    \end{align*}
    holds for all \( \w \in \R^d \) and \( \z \in \calZ \).
\end{definition}
This condition is called \emph{maximal} strong growth because it implies 
    \[ \max_{E} \int_{E} \norm{\grad(\w, \z)}^2 d\mu_k(\z) \leq \rho \norm{\grad(\w)}, \]
    where \( E \) is any event with non-zero probability under the measure \( \mu_k \). 
A relaxed version of this condition called strong growth was proposed by \citet{vaswani2019fast}.
\begin{definition}[Strong Growth]\label{def:sgc}
    A function-oracle pair \( \rbr{f, \oracle{}} \) satisfies strong growth with parameter \(\rho \) if
    \[ \Ek \sbr{\norm{\grad(\w, \zk)}^2} \leq \rho \norm{\grad(\w)}^2, \]
    holds for all \( k \geq 0 \) and \( \w \in \R^d \).
\end{definition}
It is straightforward to show that strong growth is indeed a weaker condition than maximal strong growth, which we do in the following lemma.
\begin{restatable}[Formulations of Strong Growth]{lemma}{sgcRelationships}\label{thm:sgc-relationships}
    Let \( \rbr{f, \oracle{}} \) be a function-oracle pair. 
    If \( \rbr{f, \oracle{}} \) satisfies maximal strong growth, then it also satisfies strong growth.
    However, strong growth does not imply maximal strong growth for general \oracle{}.  
\end{restatable} 
The proof of the above lemma is given in \autoref{app:growth-conditions} and illustrates the impracticality of maximal strong growth, which is not even satisfied for multiplicative Gaussian noise.
A simple sufficient condition for the equivalence of maximal strong and strong growth is that \( \calZ \) is finite.
\begin{restatable}{lemma}{sgcFiniteSupport}\label{lemma:sgc-finite-support}
    Let \( \rbr{f, \oracle{}} \) be a function-\ac{SFO} pair satisfying the strong growth condition with constant \( \rho \).
    Moreover, assume that the support \( \calZ \) of \oracle{} is finite and each \( \zk \) admits probability mass function \( p_k \). 
    Then \( \rbr{f, \oracle{}} \) also satisfies maximal strong growth.
\end{restatable}
An important consequence of \autoref{lemma:sgc-finite-support} is the equivalence of the maximal strong growth and strong growth conditions for finite-sum optimization.

A relaxed version of the strong growth condition is the weak growth condition, which was recently proposed by \citet{vaswani2019fast}.
\begin{definition}[Weak Growth Condition]\label{def:wgc}
    A function-oracle pair \( \rbr{f, \oracle{}} \) satisfies weak growth with parameter \(\alpha \) if
    \[ \Ek \sbr{\norm{\grad(\w, \zk)}^2} \leq \alpha L (f(\w) - f(\wopt)), \]
    holds for all \( k \geq 0 \) and \( \w \in \R^d\).
\end{definition}

We now elucidate the exact relationship between these growth conditions and interpolation.
In fact, several easy calculations are sufficient to show that growth conditions imply various forms of interpolation.
Instantiating the definition of maximal strong growth at \( \w = \wopt \) immediately shows that any \( \rbr{f, \oracle{}} \) pair satisfying maximal strong growth satisfies stationary-point interpolation.
Similarly, strong growth with \( \w = \wopt \) gives  
\[ \E_k\sbr{\grad(\wopt, \zk)} = 0, \] 
for all \( k \), after which non-negativity of the Euclidean norm guarantees that \( \grad(\wopt, \zk) = 0 \) almost-surely and stationary-point interpolation holds again.
Replicating this last argument under weak growth shows that the weak growth condition implies mixed interpolation.
The reverse implications are more involved; we establish them formally in the follow two lemmas. 
\begin{restatable}[Interpolation and Weak Growth]{lemma}{interpToWGC}~\label{lemma:interpolation-to-wgc}
    Let \( f \) be an \( L \)-smooth function and \oracle{} an \( \Lmax \) individually-smooth \ac{SFO}.
    Furthermore, assume that \( \rbr{f, \oracle{}} \) satisfy minimizer interpolation (\autoref{def:interpolation-minima}).
    Then \( \rbr{f, \oracle{}} \) satisfies the weak growth condition with parameter
    \[ \wgc = \frac{L_{\text{max}}}{L}. \]
\end{restatable}

\begin{restatable}[Interpolation and Strong Growth]{lemma}{interpToSGC}~\label{lemma:interpolation_to_sgc}
    Let \( f \) be an \( L \)-smooth function and \oracle{} an \( \Lmax \) individually-smooth \ac{SFO}.
    Furthermore, assume that \( \rbr{f, \oracle{}} \) satisfies minimizer interpolation.
    If \( f \) also satisfies the Polyak-Åojasiewicz condition with parameter \( \mu \), then \( \rbr{f, \oracle{}} \) satisfies the strong growth condition with parameter
    \[ \rho = \frac{L_{\text{max}}}{\mu}. \]
\end{restatable}
