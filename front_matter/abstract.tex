%% The following is a directive for TeXShop to indicate the main file
%!TEX root = ../main.tex

\chapter{Abstract}

\todo{Write abstract}

% Consider placing version information if you circulate multiple drafts
%\vfill
%\begin{center}
%\begin{sf}
%\fbox{Revision: \today}
%\end{sf}
%\end{center}

The focus is on establishing non-asymptotic convergence rates for stochastic, first-order optimization algorithms in the unconstrained setting. 
The analysis covers stochastic gradient descent with a fixed step-size and with an Armijo-type line-search, as well as Nesterov's accelerated gradient method with stochastic gradients.
These theoretical results are developed for general stochastic first-order oracles and cover finite-sum functions with sub-sampled gradients as a special case. 
